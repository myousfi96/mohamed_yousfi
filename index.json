[{"content":"\u003ch2 id=\"introduction\"\u003eIntroduction\u003c/h2\u003e\n\u003cp\u003eIn the realm of collaborative software development, pull requests play a pivotal role in code integration and review. However, understanding the key factors that determine the success of pull requests can be complex.\u003c/p\u003e\n\u003cp\u003eIn this blog post, we utilize machine learning to uncover insights into the crucial factors impacting pull request outcomes. By analyzing a diverse dataset collected from various repositories using the GitHub API, we reveal the factors that significantly influence the decision to merge or reject pull requests.\u003c/p\u003e\n\u003cp\u003eThrough data cleaning, feature engineering, and model training, we identify the most impactful characteristics. Our analysis highlights factors like the number of commits, review comment count, and time difference between creation and last update as key contributors to pull request success.\u003c/p\u003e\n\u003cp\u003eBy leveraging the power of machine learning, we provide valuable insights to development teams, enabling them to optimize their workflow and improve the chances of successful code integration.\u003c/p\u003e\n\u003cp\u003eJoin us as we explore the fascinating dynamics of pull requests and unlock the potential of machine learning to gain deeper understanding in this essential aspect of software development.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eNote:\u003c/strong\u003e You can download the code and Goolge Collab from github \u003cstrong\u003e\u003ca href=\"https://github.com/myousfi96/pull_request_mining\"\u003ehere\u003c/a\u003e\u003c/strong\u003e\u003c/p\u003e\n\u003ch2 id=\"what-is-a-pull-request\"\u003eWhat is a Pull Request?\u003c/h2\u003e\n\u003cp\u003eFor those who may be less familiar with the concept, a pull request is a fundamental component of the development process. It represents a formalized request to merge changes made in a branch or fork of our code repository into the main branch, typically referred to as the \u0026ldquo;master\u0026rdquo; or \u0026ldquo;main\u0026rdquo; branch. Pull requests allow team members to propose modifications, additions, or fixes, providing an opportunity for thorough review and discussion before merging the changes into the main codebase.\u003c/p\u003e\n\u003ch2 id=\"collecting-data\"\u003eCollecting data\u003c/h2\u003e\n\u003cp\u003eGitHub is the optimal resource for gathering pull requests, and I utilized the GitHub API to accomplish this task. The API offers a user-friendly and efficient approach; however, it does have a limitation of 5000 requests per hour. To ensure a diverse dataset, I selected multiple repositories to collect pull requests from. Below is a description of the collected data\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eAnsible :: 2200 PR\u003c/li\u003e\n\u003cli\u003eAiida :: 700 PR\u003c/li\u003e\n\u003cli\u003ePandas ::  2000 PR\u003c/li\u003e\n\u003cli\u003eMatplotlib :: 1900 PR\u003c/li\u003e\n\u003cli\u003eNNI :: 1600 PR\u003c/li\u003e\n\u003cli\u003eJinja :: 700 PR\u003c/li\u003e\n\u003cli\u003eGym :: 1000 PR\u003c/li\u003e\n\u003cli\u003eDjango :: 6800 PR\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eTotal: 16900 Pull Requests!\u003c/p\u003e\n\u003cp\u003eI collected the following information from each pull request:\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e\u003cstrong\u003emerged_at:\u003c/strong\u003e Indicates the date and time of the merge.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eauthor_followers:\u003c/strong\u003e Represents the number of followers the author has.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eupdated_at:\u003c/strong\u003e Specifies the most recent update timestamp.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003ecreated_at:\u003c/strong\u003e Indicates the pull request\u0026rsquo;s creation date.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003erequested_reviewers:\u003c/strong\u003e Shows the count of requested reviewers.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003erepo_size:\u003c/strong\u003e Represents the size of the entire repository.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003erepo_open_issues_count:\u003c/strong\u003e Indicates the current number of open issues in the repository.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003erepo_watchers:\u003c/strong\u003e Represents the current count of users watching the repository.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eauthor_association:\u003c/strong\u003e Indicates the role or association of the author.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003emerged:\u003c/strong\u003e A boolean value indicating whether the pull request was merged (true) or not (false).\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003ecommits:\u003c/strong\u003e Specifies the number of commits associated with the pull request.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eadditions:\u003c/strong\u003e Represents the number of lines added in the pull request.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003edeletions:\u003c/strong\u003e Indicates the number of lines removed in the pull request.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003echanged_files:\u003c/strong\u003e Specifies the number of files changed in the pull request.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003ebody_length:\u003c/strong\u003e Represents the length of the pull request description.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003emergable_status\u003c/strong\u003e: Give information if the pull request can be merged or not.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003ecomments_count\u003c/strong\u003e: The number of comments in this pull request.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003ereview_comments_count\u003c/strong\u003e: The number of review comments in this pull request.\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003eOnce I have collected the pull requests from each repository, I save the data in a file format known as JSON. This allows for efficient storage and retrieval of the gathered information.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eNote:\u003c/strong\u003e It is important to mention that all the pull requests that have been collected are in a closed state, indicating that they have either been merged or rejected.\u003c/p\u003e\n\u003ch2 id=\"data-cleaning-and-features-engineering\"\u003eData cleaning and Features Engineering\u003c/h2\u003e\n\u003cp\u003eAfter collecting the data and saving it in a JSON file, I will load it into my Google Colab project and convert it into a Pandas object. Utilizing the functionality provided by Pandas, I will use the following command to obtain a descriptive summary of the data:\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode class=\"language-pyhton\" data-lang=\"pyhton\"\u003edf.info()\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003eI got this result:\u003c/p\u003e\n\u003cimg src=\"/images/post/data_info.PNG\" alt= “” width=\"500\" height=\"500\"\u003e\n\u003cbr\u003e\u003cbr\u003e\nAs we can observe, the collected data consists of multiple data types, which need to be converted to a unified type (int64). To accomplish this, I employed the \"astype(int)\" function.\n\u003cbr\u003e\u003cbr\u003e\n\u003cp\u003eAdditionally, upon examining the provided photo, we noticed the presence of null values in the \u0026ldquo;body_length\u0026rdquo; column. To address this issue, we opted to remove the rows containing null values, utilizing the \u0026ldquo;dropna\u0026rdquo; function.\u003c/p\u003e\n\u003cp\u003eFurthermore, it came to our attention that there are two datetime objects, namely \u0026ldquo;created_at\u0026rdquo; and \u0026ldquo;updated_at,\u0026rdquo; which cannot be directly utilized in the model. To overcome this challenge, we created a new variable that captures the time duration between the creation of the pull request and its last update. This newly created feature proves to be more meaningful and suitable for incorporation into our model.\u003c/p\u003e\n\u003cp\u003eHere is the code encompassing all the aforementioned operations:\n\u003cbr\u003e\u003cbr\u003e\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-python\" data-lang=\"python\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003edf \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e df\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003edropna()\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003edf[\u003cspan style=\"color:#e6db74\"\u003e\u0026#39;time_diffrence\u0026#39;\u003c/span\u003e] \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e (df[\u003cspan style=\"color:#e6db74\"\u003e\u0026#39;updated_at\u0026#39;\u003c/span\u003e] \u003cspan style=\"color:#f92672\"\u003e-\u003c/span\u003e df[\u003cspan style=\"color:#e6db74\"\u003e\u0026#39;created_at\u0026#39;\u003c/span\u003e])\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003edt\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003etotal_seconds()\u003cspan style=\"color:#f92672\"\u003e/\u003c/span\u003e\u003cspan style=\"color:#ae81ff\"\u003e60\u003c/span\u003e\u003cspan style=\"color:#f92672\"\u003e/\u003c/span\u003e\u003cspan style=\"color:#ae81ff\"\u003e60\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003edf\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003edrop(\u003cspan style=\"color:#e6db74\"\u003e\u0026#39;updated_at\u0026#39;\u003c/span\u003e, axis\u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e\u003cspan style=\"color:#ae81ff\"\u003e1\u003c/span\u003e, inplace\u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e\u003cspan style=\"color:#66d9ef\"\u003eTrue\u003c/span\u003e)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003edf\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003edrop(\u003cspan style=\"color:#e6db74\"\u003e\u0026#39;created_at\u0026#39;\u003c/span\u003e, axis\u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e\u003cspan style=\"color:#ae81ff\"\u003e1\u003c/span\u003e, inplace\u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e\u003cspan style=\"color:#66d9ef\"\u003eTrue\u003c/span\u003e)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003edf[\u003cspan style=\"color:#e6db74\"\u003e\u0026#39;time_diffrence\u0026#39;\u003c/span\u003e] \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e df[\u003cspan style=\"color:#e6db74\"\u003e\u0026#39;time_diffrence\u0026#39;\u003c/span\u003e]\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eastype(int)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003edf[\u003cspan style=\"color:#e6db74\"\u003e\u0026#39;body_length\u0026#39;\u003c/span\u003e] \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e df[\u003cspan style=\"color:#e6db74\"\u003e\u0026#39;body_length\u0026#39;\u003c/span\u003e]\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eastype(int)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003edf[\u003cspan style=\"color:#e6db74\"\u003e\u0026#39;merged\u0026#39;\u003c/span\u003e] \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e df[\u003cspan style=\"color:#e6db74\"\u003e\u0026#39;merged\u0026#39;\u003c/span\u003e]\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eastype(int)\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003ch3 id=\"one-hot-encoding\"\u003eOne hot Encoding\u003c/h3\u003e\n\u003cp\u003eUpon revisiting our data, we observe the presence of a feature called \u0026ldquo;author_association.\u0026rdquo; This feature is an object that represents one of the following variables: [COLLABORATOR, CONTRIBUTOR, MEMBER, NONE]. However, we cannot directly use this object in our model. To address this, we need to perform a preprocessing step known as one-hot encoding. This process will generate a separate feature for each possible value within the object.\u003c/p\u003e\n\u003cp\u003eTo accomplish this, I implemented the following code, which performed the one-hot encoding:\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-python\" data-lang=\"python\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003eone_hot \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e pd\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eget_dummies(df[\u003cspan style=\"color:#e6db74\"\u003e\u0026#39;author_association\u0026#39;\u003c/span\u003e], prefix\u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e\u003cspan style=\"color:#e6db74\"\u003e\u0026#39;author_association\u0026#39;\u003c/span\u003e)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003edf \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e pd\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003econcat([df, one_hot], axis\u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e\u003cspan style=\"color:#ae81ff\"\u003e1\u003c/span\u003e)\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eBy executing this code, we successfully transformed the \u0026lsquo;author_association\u0026rsquo; feature into individual binary features, allowing us to utilize them effectively in our model.\u003c/p\u003e\n\u003ch3 id=\"data-leakage\"\u003eData Leakage\u003c/h3\u003e\n\u003cp\u003eFinally, we encounter one remaining issue with our data. Since our goal is to build a model that predicts whether a pull request will be merged or not, we must address the inclusion of the \u0026ldquo;mergable_status\u0026rdquo; feature. Utilizing this particular feature in our model would introduce data leakage, as it would provide direct insight into the prediction label. Consequently, to ensure the integrity and accuracy of our model, I have decided to remove this feature from the dataset.\u003c/p\u003e\n\u003ch3 id=\"data-insights\"\u003eData insights\u003c/h3\u003e\n\u003cp\u003eTo ensure diversity within our dataset, I calculated the percentage of merged pull requests for each repository and also determined the average number of commits. These metrics provide valuable insights into the distribution and characteristics of the data, contributing to a more comprehensive and representative dataset.\u003c/p\u003e\n\u003cimg src=\"/images/post/data_insights.PNG\" alt= “” width=\"500\" height=\"400\"\u003e\n\u003cbr\u003e\u003cbr\u003e\n\u003cp\u003eNow, let\u0026rsquo;s proceed with splitting our data into training, validation, and testing sets. This can be achieved using the following simple code:\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-python\" data-lang=\"python\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#f92672\"\u003efrom\u003c/span\u003e fast_ml.model_development \u003cspan style=\"color:#f92672\"\u003eimport\u003c/span\u003e train_valid_test_split\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003eX_train, y_train, X_valid, y_valid, X_test, y_test \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e train_valid_test_split(df, target \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e \u003cspan style=\"color:#e6db74\"\u003e\u0026#39;merged\u0026#39;\u003c/span\u003e, \n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e                                                                            train_size\u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e\u003cspan style=\"color:#ae81ff\"\u003e0.8\u003c/span\u003e, valid_size\u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e\u003cspan style=\"color:#ae81ff\"\u003e0.1\u003c/span\u003e, test_size\u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e\u003cspan style=\"color:#ae81ff\"\u003e0.1\u003c/span\u003e)\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eFollowing the data splitting process, let\u0026rsquo;s proceed by visualizing the distribution of our standardized training data using a box plot. This plot will provide us with valuable insights into the distribution of our data. Below is the code I used to generate the box plot:\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-python\" data-lang=\"python\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003efig, axs \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e plt\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003esubplots(\u003cspan style=\"color:#ae81ff\"\u003e1\u003c/span\u003e,\u003cspan style=\"color:#ae81ff\"\u003e1\u003c/span\u003e,figsize\u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e(\u003cspan style=\"color:#ae81ff\"\u003e10\u003c/span\u003e,\u003cspan style=\"color:#ae81ff\"\u003e8\u003c/span\u003e))\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003eaxs\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eset_title(\u003cspan style=\"color:#e6db74\"\u003e\u0026#39;Feature Analysis\u0026#39;\u003c/span\u003e)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003eaxs\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eset_xlabel(\u003cspan style=\"color:#e6db74\"\u003e\u0026#39;Normalized Values\u0026#39;\u003c/span\u003e)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003epd\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eDataFrame(data\u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003eX_train_s, columns\u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003edf\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003ecolumns)\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eboxplot(figsize\u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e(\u003cspan style=\"color:#ae81ff\"\u003e10\u003c/span\u003e,\u003cspan style=\"color:#ae81ff\"\u003e8\u003c/span\u003e), rot\u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e\u003cspan style=\"color:#ae81ff\"\u003e90\u003c/span\u003e, ax \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e axs, showfliers\u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e\u003cspan style=\"color:#66d9ef\"\u003eFalse\u003c/span\u003e)\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eAnd here is the result:\u003c/p\u003e\n\u003cimg src=\"/images/post/boxplot.PNG\" alt= “” width=\"600\" height=\"500\"\u003e\n\u003cbr\u003e\u003cbr\u003e\n\u003ch2 id=\"train-and-evaluate\"\u003eTrain and Evaluate\u003c/h2\u003e\n\u003cp\u003eNow, it\u0026rsquo;s time to train our data. Since our objective is classification, we will employ a simple Logistic Regression model from the sklearn library. Subsequently, we will generate a confusion matrix and calculate the accuracy, recall, and precision scores. Here is the code:\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-python\" data-lang=\"python\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#f92672\"\u003efrom\u003c/span\u003e sklearn.linear_model \u003cspan style=\"color:#f92672\"\u003eimport\u003c/span\u003e LogisticRegression\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#f92672\"\u003eimport\u003c/span\u003e matplotlib.pyplot \u003cspan style=\"color:#66d9ef\"\u003eas\u003c/span\u003e plt\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003elin_reg \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e LogisticRegression()\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003elin_reg\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003efit(X_train_s, y_train)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003ey_train_pred \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e lin_reg\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003epredict(X_train_s)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003ey_test_pred \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e lin_reg\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003epredict(x_test_s)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#f92672\"\u003efrom\u003c/span\u003e sklearn \u003cspan style=\"color:#f92672\"\u003eimport\u003c/span\u003e metrics\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003econfusion_matrix \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e metrics\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003econfusion_matrix(y_train, y_train_pred)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003ecm_display \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e metrics\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eConfusionMatrixDisplay(confusion_matrix \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e confusion_matrix, display_labels \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e [\u003cspan style=\"color:#66d9ef\"\u003eFalse\u003c/span\u003e, \u003cspan style=\"color:#66d9ef\"\u003eTrue\u003c/span\u003e])\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003ecm_display\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eplot()\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003eplt\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eshow()\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003eAccuracy \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e metrics\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eaccuracy_score(y_train, y_train_pred)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003eprint(Accuracy)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003eprint(metrics\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003erecall_score(y_train, y_train_pred))\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003eprint(metrics\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eprecision_score(y_train, y_train_pred))\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003eprint(metrics\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003ef1_score(y_train, y_train_pred))\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eHere is the result of evaluating the model using the test data:\u003c/p\u003e\n\u003cimg src=\"/images/post/metrix.PNG\" alt= “” width=\"600\" height=\"500\"\u003e\n\u003cbr\u003e\u003cbr\u003e\n\u003cp\u003eAccuracy = 0.8153846153846154\u003c/p\u003e\n\u003cp\u003eRecall = 0.9672489082969432\u003c/p\u003e\n\u003cp\u003ePrecision = 0.8083941605839416\u003c/p\u003e\n\u003cp\u003eF1 score = 0.8807157057654076\u003c/p\u003e\n\u003ch3 id=\"deep-learning\"\u003eDeep Learning\u003c/h3\u003e\n\u003cp\u003eAfter utilizing the logistic regression model, I proceeded to explore the effectiveness of a neural network model in capturing non-linear relationships between features. Although the neural network model produced slightly improved results, in my opinion, the marginal gain does not justify its usage in our specific application.\u003c/p\u003e\n\u003cp\u003eBelow is the code to build and train the neural network:\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-python\" data-lang=\"python\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#f92672\"\u003eimport\u003c/span\u003e tensorflow \u003cspan style=\"color:#66d9ef\"\u003eas\u003c/span\u003e tf\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003etf\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003erandom\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eset_seed(\u003cspan style=\"color:#ae81ff\"\u003e42\u003c/span\u003e)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003emodel \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e tf\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003ekeras\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eSequential([\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    tf\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003ekeras\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003elayers\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eDense(\u003cspan style=\"color:#ae81ff\"\u003e128\u003c/span\u003e, activation\u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e\u003cspan style=\"color:#e6db74\"\u003e\u0026#39;relu\u0026#39;\u003c/span\u003e),\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    tf\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003ekeras\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003elayers\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eDense(\u003cspan style=\"color:#ae81ff\"\u003e256\u003c/span\u003e, activation\u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e\u003cspan style=\"color:#e6db74\"\u003e\u0026#39;relu\u0026#39;\u003c/span\u003e),\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    tf\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003ekeras\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003elayers\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eDense(\u003cspan style=\"color:#ae81ff\"\u003e1\u003c/span\u003e, activation\u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e\u003cspan style=\"color:#e6db74\"\u003e\u0026#39;sigmoid\u0026#39;\u003c/span\u003e)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e])\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003emodel\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003ecompile(\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    loss\u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003etf\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003ekeras\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003elosses\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003ebinary_crossentropy,\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    optimizer\u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003etf\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003ekeras\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eoptimizers\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eAdam(lr\u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e\u003cspan style=\"color:#ae81ff\"\u003e0.03\u003c/span\u003e),\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    metrics\u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e[\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e        tf\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003ekeras\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003emetrics\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eBinaryAccuracy(name\u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e\u003cspan style=\"color:#e6db74\"\u003e\u0026#39;accuracy\u0026#39;\u003c/span\u003e),\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e        tf\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003ekeras\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003emetrics\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003ePrecision(name\u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e\u003cspan style=\"color:#e6db74\"\u003e\u0026#39;precision\u0026#39;\u003c/span\u003e),\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e        tf\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003ekeras\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003emetrics\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eRecall(name\u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e\u003cspan style=\"color:#e6db74\"\u003e\u0026#39;recall\u0026#39;\u003c/span\u003e)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    ]\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003emy_callback \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e tf\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003ekeras\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003ecallbacks\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eEarlyStopping(monitor\u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e\u003cspan style=\"color:#e6db74\"\u003e\u0026#34;val_loss\u0026#34;\u003c/span\u003e, patience\u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e\u003cspan style=\"color:#ae81ff\"\u003e10\u003c/span\u003e)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003ehistory \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e model\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003efit(X_train_s, y_train, epochs\u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e\u003cspan style=\"color:#ae81ff\"\u003e50\u003c/span\u003e, validation_data \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e (x_validate_s, y_valid), callbacks\u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e[my_callback])\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003ch3 id=\"features-importance\"\u003eFeatures Importance\u003c/h3\u003e\n\u003cp\u003eThis is the most critical aspect of the project, as it reveals which features of the pull request have the greatest impact on the model\u0026rsquo;s decision-making process. By analyzing these findings, we can determine the most significant characteristics of a pull request.\u003c/p\u003e\n\u003cimg src=\"/images/post/feature_importance.PNG\" alt= “” width=\"800\" height=\"800\"\u003e\n\u003cbr\u003e\u003cbr\u003e\n\u003cp\u003eAs depicted in the image above, we observe that the most influential feature on the model\u0026rsquo;s decision-making process is the number of commits in the pull request. Interestingly, this feature has a negative impact, indicating that a higher number of commits may make it more challenging to have the pull request merged. Conversely, the \u0026ldquo;review_comments_count\u0026rdquo; feature exhibits a positive impact, suggesting that an increased count of review comments positively influences the model\u0026rsquo;s decision.\u003c/p\u003e\n\u003cp\u003eFurthermore, it is worth noting the presence of the \u0026ldquo;time_difference\u0026rdquo; feature, which represents the duration between the creation of the pull request and its last update. This feature has a negative impact, indicating that a longer duration without updates from the author may make it more difficult to merge the pull request successfully.\u003c/p\u003e\n\u003cp\u003eBy analyzing these findings, we can gain insights into the most critical characteristics of a pull request and their influence on the model\u0026rsquo;s decision.\u003c/p\u003e\n\u003ch2 id=\"conclusion\"\u003econclusion\u003c/h2\u003e\n\u003cp\u003eIn conclusion, our analysis of pull request data using machine learning provided valuable insights into the factors that impact the success of code integration. By examining a diverse dataset from multiple repositories, we identified crucial contributors such as the number of commits, review comment count, and time difference between creation and last update.\u003c/p\u003e\n\u003cp\u003eThese findings offer development teams actionable information to optimize their workflow and enhance the likelihood of successful pull request merging. Leveraging machine learning empowers teams to make data-driven decisions, improving collaboration and code integration within their projects.\u003c/p\u003e\n\u003cp\u003eBy understanding the significant characteristics of pull requests and their influence on the model\u0026rsquo;s decision-making process, teams can prioritize their efforts and create a more efficient and collaborative coding environment.\u003c/p\u003e\n","description":"","image":"/images/mining_software.jpg","permalink":"https://myousfi96.github.io/blogs/mining-software-pull-request/","title":"Leveraging Machine Learning to Identify Optimal Pull Request Characteristics"}]